{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "about-heavy",
   "metadata": {},
   "source": [
    "## 0. Libarary 불러오기 및 경로설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cubic-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "built-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트레인 데이터셋 폴더 경로\n",
    "test_dir = '/opt/ml/input/data/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6529d7db-a30e-4925-b394-a27a405b910f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000001</th>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000002</th>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>52</td>\n",
       "      <td>000002_female_Asian_52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000004</th>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>000004_male_Asian_54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000005</th>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>58</td>\n",
       "      <td>000005_female_Asian_58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000006</th>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>000006_female_Asian_59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gender   race  age                    path\n",
       "id                                                \n",
       "000001  female  Asian   45  000001_female_Asian_45\n",
       "000002  female  Asian   52  000002_female_Asian_52\n",
       "000004    male  Asian   54    000004_male_Asian_54\n",
       "000005  female  Asian   58  000005_female_Asian_58\n",
       "000006  female  Asian   59  000006_female_Asian_59"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDA 데이터 개략\n",
    "train_ds = pd.read_csv(test_dir+'/train.csv',  index_col='id')\n",
    "train_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "403811f3-b12e-4de3-96c6-95b1c1b7b51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "000001    000001_female_Asian_45\n",
       "000002    000002_female_Asian_52\n",
       "000004      000004_male_Asian_54\n",
       "000005    000005_female_Asian_58\n",
       "000006    000006_female_Asian_59\n",
       "                   ...          \n",
       "006954      006954_male_Asian_19\n",
       "006955      006955_male_Asian_19\n",
       "006956      006956_male_Asian_19\n",
       "006957      006957_male_Asian_20\n",
       "006959      006959_male_Asian_19\n",
       "Name: path, Length: 2700, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75b3fd73-38d3-4a53-b11f-b80bfa51459d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "000001    000001_female_Asian_45\n",
       "000002    000002_female_Asian_52\n",
       "000004      000004_male_Asian_54\n",
       "000005    000005_female_Asian_58\n",
       "000006    000006_female_Asian_59\n",
       "                   ...          \n",
       "006954      006954_male_Asian_19\n",
       "006955      006955_male_Asian_19\n",
       "006956      006956_male_Asian_19\n",
       "006957      006957_male_Asian_20\n",
       "006959      006959_male_Asian_19\n",
       "Name: path, Length: 2700, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52e4a819-8472-420c-9a13-e6a1ce378ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling by 3 class\n",
    "# by mask class\n",
    "for person in train_ds['path']:\n",
    "    os.chdir('/opt/ml/input/data')\n",
    "    img_lst = os.listdir(f'train/images/{person}')\n",
    "    person_id = person[0:6]\n",
    "    for photo_n in img_lst:\n",
    "        fl = photo_n[0]\n",
    "        if fl == 'm':\n",
    "            shutil.copy(f'train/images/{person}/{photo_n}', f'train_3class/mask/correct/{person_id}_{photo_n}')\n",
    "        elif fl == 'i':\n",
    "            shutil.copy(f'train/images/{person}/{photo_n}', f'train_3class/mask/incorrect/{person_id}_{photo_n}')\n",
    "        elif fl == 'n':\n",
    "            shutil.copy(f'train/images/{person}/{photo_n}', f'train_3class/mask/no/{person_id}_{photo_n}')\n",
    "            \n",
    "# by gender class\n",
    "for person in train_ds['path']:\n",
    "    os.chdir('/opt/ml/input/data')\n",
    "    img_lst = os.listdir(f'train/images/{person}')\n",
    "    gender= person[7:13]\n",
    "    person_id = person[0:6]\n",
    "    for photo_n in img_lst:\n",
    "        fl = photo_n[0]\n",
    "        if fl != '.':\n",
    "            if gender == 'female':\n",
    "                shutil.copy(f'train/images/{person}/{photo_n}', f'train_3class/gender/female/{person_id}_{photo_n}')\n",
    "            else:\n",
    "                shutil.copy(f'train/images/{person}/{photo_n}', f'train_3class/gender/male/{person_id}_{photo_n}')\n",
    "                \n",
    "# by age class\n",
    "for person in train_ds['path']:\n",
    "    os.chdir('/opt/ml/input/data')\n",
    "    img_lst = os.listdir(f'train/images/{person}')\n",
    "    age = int(person[-2:])\n",
    "    person_id = person[0:6]\n",
    "    for photo_n in img_lst:\n",
    "        fl = photo_n[0]\n",
    "        if fl != '.':\n",
    "            if age < 30:\n",
    "                shutil.copy(f'train/images/{person}/{photo_n}', f'train_3class/age/under30/{person_id}_{photo_n}')\n",
    "            elif age < 60:\n",
    "                shutil.copy(f'train/images/{person}/{photo_n}', f'train_3class/age/30to60/{person_id}_{photo_n}')\n",
    "            else:\n",
    "                shutil.copy(f'train/images/{person}/{photo_n}', f'train_3class/age/from60/{person_id}_{photo_n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30ec62f-b20d-4ba9-badb-ce4068b36caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling by 18 class\n",
    "for person in train_ds['path']:\n",
    "    os.chdir('/opt/ml/input/data')\n",
    "    img_lst = os.listdir(f'train/images/{person}')\n",
    "    person_id = person[0:6]\n",
    "    gender= person[7:13]\n",
    "    age = int(person[-2:])\n",
    "    for photo_n in img_lst:\n",
    "        fl = photo_n[0]\n",
    "        if fl == 'm':\n",
    "            if gender != 'female':\n",
    "                if age < 30:\n",
    "                    shutil.copy(f'train/images/{person}/{photo_n}', f'train_18class/0/{person_id}_{photo_n}')\n",
    "                elif age < 60:\n",
    "                    shutil.copy(f'train/images/{person}/{photo_n}', f'train_18class/1/{person_id}_{photo_n}')\n",
    "                else:\n",
    "                    shutil.copy(f'train/images/{person}/{photo_n}', f'train_18class/2/{person_id}_{photo_n}')\n",
    "            else:\n",
    "                if age < 30:\n",
    "                    shutil.copy(f'train/images/{person}/{photo_n}', f'train_18class/3/{person_id}_{photo_n}')\n",
    "                elif age < 60:\n",
    "                    shutil.copy(f'train/images/{person}/{photo_n}', f'train_18class/4/{person_id}_{photo_n}')\n",
    "                else:\n",
    "                    shutil.copy(f'train/images/{person}/{photo_n}', f'train_18class/5/{person_id}_{photo_n}')\n",
    "        elif fl == 'i':\n",
    "            if gender != 'female':\n",
    "                if age < 30:\n",
    "                    shutil.copy(f'train/images/{person}/{photo_n}', f'train_18class/6/{person_id}_{photo_n}')\n",
    "                elif age < 60:\n",
    "                    shutil.copy(f'train/images/{person}/{photo_n}', f'train_18class/7/{person_id}_{photo_n}')\n",
    "                else:\n",
    "                    shutil.copy(f'train/images/{person}/{photo_n}', f'train_18class/8/{person_id}_{photo_n}')\n",
    "            else:\n",
    "                if age < 30:\n",
    "                    shutil.copy(f'train/images/{person}/{photo_n}', f'train_18class/9/{person_id}_{photo_n}')\n",
    "                elif age < 60:\n",
    "                    shutil.copy(f'train/images/{person}/{photo_n}', f'train_18class/10/{person_id}_{photo_n}')\n",
    "                else:\n",
    "                    shutil.copy(f'train/images/{person}/{photo_n}', f'train_18class/11/{person_id}_{photo_n}')\n",
    "        elif fl == 'n':\n",
    "            if gender != 'female':\n",
    "                if age < 30:\n",
    "                    shutil.copy(f'train/images/{person}/{photo_n}', f'train_18class/12/{person_id}_{photo_n}')\n",
    "                elif age < 60:\n",
    "                    shutil.copy(f'train/images/{person}/{photo_n}', f'train_18class/13/{person_id}_{photo_n}')\n",
    "                else:\n",
    "                    shutil.copy(f'train/images/{person}/{photo_n}', f'train_18class/14/{person_id}_{photo_n}')\n",
    "            else:\n",
    "                if age < 30:\n",
    "                    shutil.copy(f'train/images/{person}/{photo_n}', f'train_18class/15/{person_id}_{photo_n}')\n",
    "                elif age < 60:\n",
    "                    shutil.copy(f'train/images/{person}/{photo_n}', f'train_18class/16/{person_id}_{photo_n}')\n",
    "                else:\n",
    "                    shutil.copy(f'train/images/{person}/{photo_n}', f'train_18class/17/{person_id}_{photo_n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c96a7d3-7d1e-40d1-84ca-4f6f14a6cfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "000001    000001_female_Asian_45\n",
       "000002    000002_female_Asian_52\n",
       "000004      000004_male_Asian_54\n",
       "000005    000005_female_Asian_58\n",
       "000006    000006_female_Asian_59\n",
       "                   ...          \n",
       "006954      006954_male_Asian_19\n",
       "006955      006955_male_Asian_19\n",
       "006956      006956_male_Asian_19\n",
       "006957      006957_male_Asian_20\n",
       "006959      006959_male_Asian_19\n",
       "Name: path, Length: 2700, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bcf9629e-419a-4792-b4ac-d6b3cdb719d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male ratio 38.592592592592595 %\n"
     ]
    }
   ],
   "source": [
    "row_count = train_ds.count()[0]\n",
    "male_count = train_ds[train_ds['gender'] == 'male']['gender'].count()\n",
    "print('male ratio', male_count / row_count * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be18f0f-7ca0-4872-8df1-a1dfd7c9d507",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count = train_ds.count()[0]\n",
    "male_count = train_ds[train_ds['gender'] == 'male']['gender'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-organizer",
   "metadata": {},
   "source": [
    "## 1. Model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acknowledged-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1000):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-channels",
   "metadata": {},
   "source": [
    "## 2. Test Dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "extensive-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-feelings",
   "metadata": {},
   "source": [
    "## 3. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "coral-shade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "model = MyModel(num_classes=18).to(device)\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-sample",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
